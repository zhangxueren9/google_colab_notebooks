{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentence_classify.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhangxueren9/google_colab_notebooks/blob/master/sentence_classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "MxB5A5jpmoCN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#某法律网站用户提问自动分类试验\n",
        "\n",
        "##数据部分\n",
        "\n",
        "1.   数据来源：国内律师网站\n",
        "\n",
        "1.   数据处理：将用户提问数据(title部分)经 切词-->去停用词-->选取高频词(top5000)-->过滤低频分类，得到句子向量和分类。\n",
        "\n",
        "1.   数据说明：处理后数据保存在cleared_and_filter_text_v1.1.1.csv中，句子和标签已Tab(\"\\t\")分割。句子为json字符串list类型\n",
        "\n",
        "\n",
        "##模型部分\n",
        "模型使用pytorch框架实现，模型结构：embedding -->双向LSTM-->全连接层1-->全连接层2  \n",
        "全连接层使用SoftMax激活函数。\n",
        "##试验结果\n",
        "模型效果很差，损失不能随训练步骤增加而降低。\n",
        "##分析\n",
        "造成模型不收敛的主要原因，句子长度太短无法获句子所含信息无法支持分类，脏数据太多。\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "3RCLnpOc-igg",
        "colab_type": "code",
        "outputId": "0da3eecb-4f63-4d3c-e1bd-88f901e7b7ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "08zEwGCQ7wbG",
        "colab_type": "code",
        "outputId": "b54cb5ec-a0e3-4359-8732-2ef864d522b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1-cp36-cp36m-win_amd64.whl\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mtorch-1.0.1-cp36-cp36m-win_amd64.whl is not a supported wheel on this platform.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dB7q0E5W8vcx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_FILE = \"dataset/cleared_and_filter_text_v1.1.1.csv\"\n",
        "CATEGORY_SIZE = 10\n",
        "WORD_VOC_SIZE = 5000\n",
        "MAX_SENTENCE_LEN = 25\n",
        "NUM_DIRECTIONS = 2\n",
        "\n",
        "EMBEDDING_SIZE = 100\n",
        "HIDDEN_SIZE = 512\n",
        "NUM_LAYERS = 1\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "LEARN_RATE = 0.05\n",
        "NUM_EPOCHS = 100\n",
        "\n",
        "\n",
        "MODEL_PATH = \"model_file/sentiment_lstm_model_v1.1.1.pkl\"\n",
        "\n",
        "TEST_SIZE = 0.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DUWROzwx83D6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def decode_one_hot_label(one_hot_label):\n",
        "    one_hot_label = one_hot_label.tolist()\n",
        "    label = \"\"\n",
        "    index = np.argmax(one_hot_label)\n",
        "    label += str(index)\n",
        "    return label\n",
        "\n",
        "\n",
        "def encode_one_hot_label(label):\n",
        "    one_hot_label = np.zeros(shape=(CATEGORY_SIZE,)).astype(np.float)\n",
        "    one_hot_label[int(label) - 1] = 1.0\n",
        "    return one_hot_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RDnU6PuL9AjX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class SentenceCategoryDataset(Dataset):\n",
        "    def __init__(self, sentence_lines, max_sentence_len=MAX_SENTENCE_LEN, word_voc_size=WORD_VOC_SIZE,\n",
        "                 category_size=CATEGORY_SIZE):\n",
        "        self.sentence_lines = sentence_lines\n",
        "        self.max_sentence_len = max_sentence_len\n",
        "        self.word_voc_size = word_voc_size\n",
        "        self.category_size = category_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentence_lines)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        sentence = np.zeros(shape=(self.max_sentence_len,)).astype(np.long)\n",
        "        sentence_line = self.sentence_lines[item]\n",
        "        splits = sentence_line.split(\"\\t\")\n",
        "        words = json.loads(splits[0], encoding=\"utf8\")\n",
        "#         words = splits[0:-1]\n",
        "        for idx, word in enumerate(words):\n",
        "            if idx > self.max_sentence_len - 1:\n",
        "                break\n",
        "            sentence[idx] = int(words[idx])\n",
        "        category = splits[-1]\n",
        "        category = encode_one_hot_label(category)\n",
        "        return sentence, category\n",
        "\n",
        "\n",
        "def get_data_loader(data_file=DATA_FILE, batch_size=BATCH_SIZE, test_size=TEST_SIZE):\n",
        "    train_lines = []\n",
        "    test_lines = []\n",
        "    with open(data_file) as fi:\n",
        "        for line in fi:\n",
        "            line = line.strip()\n",
        "            if random.random() > test_size:\n",
        "                train_lines.append(line)\n",
        "            else:\n",
        "                test_lines.append(line)\n",
        "\n",
        "    train_data_loader = DataLoader(SentenceCategoryDataset(train_lines), batch_size=batch_size, shuffle=True)\n",
        "    test_data_loader = DataLoader(SentenceCategoryDataset(test_lines), batch_size=1, shuffle=True)\n",
        "    return train_data_loader, test_data_loader\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PKowYEWj9rI6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as  F\n",
        "\n",
        "\n",
        "\n",
        "class SentimentLstm(nn.Module):\n",
        "    def __init__(self, word_voc_size=WORD_VOC_SIZE + 1, embedding_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE,\n",
        "                 num_layers=NUM_LAYERS, num_directions=NUM_DIRECTIONS, batch_size=BATCH_SIZE,\n",
        "                 category_size=CATEGORY_SIZE):\n",
        "        super(SentimentLstm, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_directions = num_directions\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embedding = nn.Embedding(word_voc_size, embedding_size)\n",
        "        torch.manual_seed(1)\n",
        "        self.is_bi_lstm = num_directions == 2\n",
        "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, batch_first=True, bidirectional=self.is_bi_lstm)\n",
        "        if self.is_bi_lstm:\n",
        "            self.liner1 = nn.Linear(hidden_size * 2, 128)\n",
        "        else:\n",
        "            self.liner1 = nn.Linear(hidden_size, 128)\n",
        "        self.liner2 = nn.Linear(128, category_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        w2v = self.embedding(x)\n",
        "        w2v = w2v.view(x.shape[0], -1, self.embedding_size)\n",
        "        out, _ = self.lstm(w2v)\n",
        "        last_stat = out[:, -1, :]\n",
        "        out = F.softmax(self.liner1(last_stat), dim=1)\n",
        "        out = F.softmax(self.liner2(out), dim=1)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cUOwkUQ090Iq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train():\n",
        "    device = torch.device('cuda:0')\n",
        "    lstm = SentimentLstm()\n",
        "    lstm.train()\n",
        "    lstm.to(device)\n",
        "\n",
        "    model_dir = os.path.split(MODEL_PATH)[0]\n",
        "#     if not os.path.exists(model_dir):\n",
        "#         os.mkdir(model_dir)\n",
        "    if os.path.exists(MODEL_PATH):\n",
        "        lstm.load_state_dict(torch.load(MODEL_PATH))\n",
        "\n",
        "    print(\"init net\")\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    # criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(lstm.parameters(), lr=LEARN_RATE)\n",
        "    train_data_loader = get_data_loader()[0]\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        for i, (sentences, labels) in enumerate(train_data_loader):\n",
        "            sentences = Variable(sentences).cuda()\n",
        "            labels = Variable(labels.float()).cuda()\n",
        "            predict_labels = lstm(sentences)\n",
        "            loss = criterion(predict_labels, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if (i + 1) % 1000 == 0:\n",
        "                print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
        "            if (i + 1) % 1000 == 0:\n",
        "                torch.save(lstm.state_dict(), MODEL_PATH)  # current is model.pkl\n",
        "                print(\"save model\")\n",
        "        if epoch % 5 == 1:\n",
        "            test()\n",
        "        print(\"epoch:\", epoch, \"step:\", i, \"loss:\", loss.item())\n",
        "        torch.save(lstm.state_dict(), MODEL_PATH)  # current is model.pkl\n",
        "        print(\"save last model\")\n",
        "\n",
        "\n",
        "def test():\n",
        "    device = torch.device('cuda:0')\n",
        "    lstm = SentimentLstm()\n",
        "    lstm.eval()\n",
        "    lstm.to(device)\n",
        "    print(\"load model\")\n",
        "    start_time = time.time()\n",
        "    test_data_loader = get_data_loader()[-1]\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (sentences, labels) in enumerate(test_data_loader):\n",
        "        sentences = sentences\n",
        "        vsentences = Variable(sentences).cuda()\n",
        "        predict_label = lstm(vsentences)\n",
        "\n",
        "        predict_label = decode_one_hot_label(predict_label[0])\n",
        "        true_label = decode_one_hot_label(labels.numpy()[0])\n",
        "\n",
        "#         print(\"the predict_label %s  ---> the real label %s\" % (predict_label, true_label))\n",
        "        total += labels.size(0)\n",
        "        if (predict_label == true_label):\n",
        "            correct += 1\n",
        "        if (total % 2000 == 0):\n",
        "            print('Test Accuracy of the model on the %d test sentences: %f %%' % (total, 100 * correct / total))\n",
        "            return\n",
        "    print('Test Accuracy of the model on the %d test sentences: %f %%' % (total, 100 * correct / total))\n",
        "    end_time = time.time()\n",
        "#     print(\"avg %f secends per sentences\" % ((end_time - start_time) / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2UV9dPKw-Fwe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}